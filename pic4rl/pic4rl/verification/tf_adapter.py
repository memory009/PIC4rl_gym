#!/usr/bin/env python3
"""
TensorFlowæ¨¡å‹æƒé‡æå–é€‚é…å™¨
å°†tf2rlçš„TD3æ¨¡å‹æƒé‡è½¬æ¢ä¸ºNumPyæ ¼å¼ä¾›POLARä½¿ç”¨
"""

import numpy as np
import tensorflow as tf
import os
import pickle
import glob


class TD3WeightExtractor:
    """
    TD3æ¨¡å‹æƒé‡æå–å™¨
    
    å…¼å®¹tf2rlçš„checkpointä¿å­˜æ ¼å¼
    """
    
    def __init__(self, checkpoint_dir):
        """
        Args:
            checkpoint_dir: checkpointç›®å½•è·¯å¾„
                ä¾‹å¦‚: "../Results/20251031_120540.356112_lidar_TD3/20251031T120540.688820_TD3_"
        """
        self.checkpoint_dir = checkpoint_dir
        self.checkpoint_path = os.path.join(checkpoint_dir, "checkpoint")
        
        # æ£€æŸ¥checkpointæ–‡ä»¶
        if not os.path.exists(self.checkpoint_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°checkpointæ–‡ä»¶: {self.checkpoint_path}")
        
        # è¯»å–æœ€æ–°çš„checkpoint
        with open(self.checkpoint_path, 'r') as f:
            first_line = f.readline().strip()
            # æ ¼å¼: model_checkpoint_path: "ckpt-10"
            self.latest_ckpt = first_line.split('"')[1]
        
        print(f"âœ… æ‰¾åˆ°checkpoint: {self.checkpoint_path}")
        print(f"âœ… æœ€æ–°æ¨¡å‹: {self.latest_ckpt}")
    
    def _build_actor_network(self, state_dim=38, action_dim=2):
        """
        é‡å»ºActorç½‘ç»œç»“æ„ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        
        ç½‘ç»œç»“æ„:
            [38] â†’ [256, ReLU] â†’ [128, ReLU] â†’ [128, ReLU] â†’ [2, Tanh] â†’ Ã—max_action
        """
        from tensorflow.keras import layers, Model
        
        inputs = layers.Input(shape=(state_dim,))
        
        # éšè—å±‚1
        x = layers.Dense(256, activation='relu', name='l1')(inputs)
        
        # éšè—å±‚2
        x = layers.Dense(128, activation='relu', name='l2')(x)
        
        # éšè—å±‚3
        x = layers.Dense(128, activation='relu', name='l3')(x)
        
        # è¾“å‡ºå±‚
        outputs = layers.Dense(action_dim, activation='tanh', name='l4')(x)
        
        model = Model(inputs=inputs, outputs=outputs, name='actor')
        return model
    
    def load_actor_weights(self):
        """
        ä»checkpointåŠ è½½Actorç½‘ç»œæƒé‡
        
        Returns:
            weights: list of np.ndarray - æƒé‡çŸ©é˜µåˆ—è¡¨ [W1, W2, W3, W4]
            biases: list of np.ndarray - åç½®å‘é‡åˆ—è¡¨ [b1, b2, b3, b4]
        """
        try:
            # 1. é‡å»ºç½‘ç»œ
            print("\nğŸ“Š é‡å»ºActorç½‘ç»œ...")
            actor = self._build_actor_network()
            actor.summary()
            
            # 2. åˆ›å»ºcheckpointå¯¹è±¡
            ckpt = tf.train.Checkpoint(actor=actor)
            
            # 3. åŠ è½½æƒé‡
            ckpt_path = os.path.join(self.checkpoint_dir, self.latest_ckpt)
            status = ckpt.restore(ckpt_path)
            
            # å°è¯•åŠ è½½ï¼ˆtf2rlçš„ä¿å­˜æ–¹å¼ï¼‰
            try:
                status.expect_partial()  # å¿½ç•¥optimizerç­‰é¢å¤–å˜é‡
                print(f"âœ… æˆåŠŸä»checkpointåŠ è½½æƒé‡: {self.latest_ckpt}")
            except:
                print(f"âš ï¸ éƒ¨åˆ†æƒé‡åŠ è½½ï¼Œå°è¯•å®Œæ•´åŒ¹é…...")
                status.assert_consumed()
            
            # 4. æå–æƒé‡
            weights = []
            biases = []
            
            print("\nğŸ“¦ æå–æƒé‡...")
            for i, layer in enumerate(actor.layers):
                if isinstance(layer, tf.keras.layers.Dense):
                    w = layer.get_weights()
                    if len(w) == 2:
                        weights.append(w[0])
                        biases.append(w[1])
                        print(f"  Layer {layer.name}: W{w[0].shape}, b{w[1].shape}")
            
            # 5. éªŒè¯ç½‘ç»œç»“æ„
            expected_shapes = [
                ((38, 256), (256,)),   # éšè—å±‚1
                ((256, 128), (128,)),  # éšè—å±‚2
                ((128, 128), (128,)),  # éšè—å±‚3
                ((128, 2), (2,))       # è¾“å‡ºå±‚
            ]
            
            if len(weights) != 4:
                raise ValueError(f"âŒ é¢„æœŸ4å±‚ï¼Œå®é™…å¾—åˆ°{len(weights)}å±‚")
            
            for i, ((w_shape, b_shape), (w, b)) in enumerate(zip(expected_shapes, zip(weights, biases))):
                if w.shape != w_shape:
                    raise ValueError(f"âŒ ç¬¬{i+1}å±‚æƒé‡å½¢çŠ¶é”™è¯¯: é¢„æœŸ{w_shape}, å®é™…{w.shape}")
                if b.shape != b_shape:
                    raise ValueError(f"âŒ ç¬¬{i+1}å±‚åç½®å½¢çŠ¶é”™è¯¯: é¢„æœŸ{b_shape}, å®é™…{b.shape}")
            
            print(f"\nâœ… æƒé‡æå–æˆåŠŸï¼å…±{len(weights)}å±‚")
            return weights, biases
            
        except Exception as e:
            print(f"âŒ åŠ è½½checkpointå¤±è´¥ï¼Œå°è¯•ç›´æ¥è¯»å–å˜é‡...")
            return self._load_weights_from_checkpoint_variables()
    
    def _load_weights_from_checkpoint_variables(self):
        """
        ç›´æ¥ä»checkpointå˜é‡è¯»å–ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰
        """
        try:
            # åˆ—å‡ºæ‰€æœ‰å˜é‡
            ckpt_path = os.path.join(self.checkpoint_dir, self.latest_ckpt)
            reader = tf.train.load_checkpoint(ckpt_path)
            var_to_shape_map = reader.get_variable_to_shape_map()
            
            print("\nğŸ“‹ Checkpointä¸­çš„å˜é‡:")
            for key in sorted(var_to_shape_map.keys()):
                print(f"  {key}: {var_to_shape_map[key]}")
            
            # æå–actorç›¸å…³å˜é‡
            weights = []
            biases = []
            
            for i in range(1, 5):  # l1, l2, l3, l4
                w_key = f'actor/l{i}/kernel/.ATTRIBUTES/VARIABLE_VALUE'
                b_key = f'actor/l{i}/bias/.ATTRIBUTES/VARIABLE_VALUE'
                
                if w_key in var_to_shape_map and b_key in var_to_shape_map:
                    w = reader.get_tensor(w_key)
                    b = reader.get_tensor(b_key)
                    weights.append(w)
                    biases.append(b)
                    print(f"âœ… åŠ è½½ l{i}: W{w.shape}, b{b.shape}")
                else:
                    # å°è¯•å…¶ä»–å¯èƒ½çš„å‘½å
                    for alt_w_key in [f'actor/l{i}/kernel', f'actor/_layer{i}/kernel']:
                        if alt_w_key in [k.split('/.ATTRIBUTES')[0] for k in var_to_shape_map.keys()]:
                            full_w_key = [k for k in var_to_shape_map.keys() if alt_w_key in k][0]
                            full_b_key = full_w_key.replace('kernel', 'bias')
                            
                            w = reader.get_tensor(full_w_key)
                            b = reader.get_tensor(full_b_key)
                            weights.append(w)
                            biases.append(b)
                            print(f"âœ… åŠ è½½ l{i} (å¤‡ç”¨å‘½å): W{w.shape}, b{b.shape}")
                            break
            
            if len(weights) != 4:
                raise ValueError(f"âŒ åªæ‰¾åˆ°{len(weights)}å±‚æƒé‡")
            
            return weights, biases
            
        except Exception as e:
            print(f"âŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
            raise
    
    def extract_and_save(self, output_path=None):
        """
        æå–æƒé‡å¹¶ä¿å­˜ä¸ºpickleæ–‡ä»¶
        """
        if output_path is None:
            output_path = os.path.join(self.checkpoint_dir, "actor_weights.pkl")
        
        weights, biases = self.load_actor_weights()
        
        data = {
            'weights': weights,
            'biases': biases,
            'checkpoint': self.latest_ckpt,
            'network_structure': [
                {'input': 38, 'output': 256, 'activation': 'relu'},
                {'input': 256, 'output': 128, 'activation': 'relu'},
                {'input': 128, 'output': 128, 'activation': 'relu'},
                {'input': 128, 'output': 2, 'activation': 'tanh'}
            ]
        }
        
        with open(output_path, 'wb') as f:
            pickle.dump(data, f)
        
        print(f"âœ… æƒé‡å·²ä¿å­˜è‡³: {output_path}")
        return output_path


def verify_weight_extraction(checkpoint_dir):
    """
    éªŒè¯æƒé‡æå–æ˜¯å¦æ­£ç¡®
    """
    print("="*70)
    print("å¼€å§‹éªŒè¯æƒé‡æå–...")
    print("="*70)
    
    try:
        extractor = TD3WeightExtractor(checkpoint_dir)
        weights, biases = extractor.load_actor_weights()
        
        # éªŒè¯1: æ•°å€¼ç±»å‹
        print("\n[éªŒè¯1] æ£€æŸ¥æ•°å€¼ç±»å‹...")
        for i, (w, b) in enumerate(zip(weights, biases)):
            assert w.dtype in [np.float32, np.float64], f"æƒé‡ç±»å‹é”™è¯¯: {w.dtype}"
            assert b.dtype in [np.float32, np.float64], f"åç½®ç±»å‹é”™è¯¯: {b.dtype}"
        print("  âœ… æ‰€æœ‰æƒé‡ä¸ºæµ®ç‚¹æ•°ç±»å‹")
        
        # éªŒè¯2: æ•°å€¼èŒƒå›´
        print("\n[éªŒè¯2] æ£€æŸ¥æ•°å€¼èŒƒå›´...")
        for i, (w, b) in enumerate(zip(weights, biases)):
            w_min, w_max = w.min(), w.max()
            b_min, b_max = b.min(), b.max()
            print(f"  Layer {i+1}: W âˆˆ [{w_min:.4f}, {w_max:.4f}], b âˆˆ [{b_min:.4f}, {b_max:.4f}]")
            
            assert not np.isnan(w).any(), f"ç¬¬{i+1}å±‚æƒé‡åŒ…å«NaN"
            assert not np.isnan(b).any(), f"ç¬¬{i+1}å±‚åç½®åŒ…å«NaN"
            assert not np.isinf(w).any(), f"ç¬¬{i+1}å±‚æƒé‡åŒ…å«Inf"
            assert not np.isinf(b).any(), f"ç¬¬{i+1}å±‚åç½®åŒ…å«Inf"
        print("  âœ… æ•°å€¼èŒƒå›´æ­£å¸¸ï¼Œæ— NaN/Inf")
        
        # éªŒè¯3: å‰å‘ä¼ æ’­æµ‹è¯•
        print("\n[éªŒè¯3] å‰å‘ä¼ æ’­æµ‹è¯•...")
        test_input = np.random.randn(38).astype(np.float32)
        
        x = test_input
        for i, (w, b) in enumerate(zip(weights, biases)):
            x = np.dot(x, w) + b
            
            if i < 3:  # ReLU
                x = np.maximum(0, x)
            else:  # Tanh
                x = np.tanh(x)
        
        print(f"  æµ‹è¯•è¾“å…¥: {test_input[:5]}... (å‰5ç»´)")
        print(f"  ç½‘ç»œè¾“å‡º: {x}")
        print(f"  è¾“å‡ºèŒƒå›´: [{x.min():.6f}, {x.max():.6f}]")
        assert x.shape == (2,), f"è¾“å‡ºç»´åº¦é”™è¯¯: {x.shape}"
        assert np.all(np.abs(x) <= 1.0), f"Tanhè¾“å‡ºè¶…å‡º[-1,1]èŒƒå›´"
        print("  âœ… å‰å‘ä¼ æ’­æ­£å¸¸")
        
        print("\n" + "="*70)
        print("âœ… æƒé‡æå–éªŒè¯é€šè¿‡ï¼")
        print("="*70)
        return True
        
    except Exception as e:
        print(f"\nâŒ éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == '__main__':
    import sys
    
    if len(sys.argv) > 1:
        checkpoint_dir = sys.argv[1]
    else:
        print("ç”¨æ³•: python tf_adapter.py <checkpointç›®å½•>")
        print("ç¤ºä¾‹: python tf_adapter.py ../Results/20251031_120540.356112_lidar_TD3/20251031T120540.688820_TD3_")
        sys.exit(1)
    
    verify_weight_extraction(checkpoint_dir)